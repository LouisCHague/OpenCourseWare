head(out)
class(out)
iplotScanone(out)
# Loading our data
min1_20.df <- read_csv("C:/Users/louis/OneDrive/Desktop/cranfield/Cranfield Academic Information/group_project/test_plots/data/AR_no_min1_2020.csv")
# Splitting the data based on the chromsome (chromosome 1)
min1_20_Rid1 <- min1_20.df[min1_20.df[["chr"]] == "Rid1", ]
min1_20_Rid1
scanone(min1_20_Rid1)
iplotScanone(min1_20_Rid1)
# Load necessary libraries
library(qtl)
library(qtlcharts)
library(readr)
# Load data
min1_20.df <- read_csv("C:/Users/louis/OneDrive/Desktop/cranfield/Cranfield Academic Information/group_project/test_plots/data/AR_no_min1_2020.csv")
# Subset data based on the chromosome ("Rid1")
min1_20_Rid1 <- min1_20.df[min1_20.df$chr == "Rid1", ]
# Create a cross object
cross_obj <- read.cross(format = "data.frame", data = min1_20_Rid1)
# Install necessary packages if not already installed
install.packages("vcfR")
install.packages("ggplot2")
install.packages("dplyr")
library(vcfR)
library(ggplot2)
library(dplyr)
# Read the VCF files
vcf1 <- read.vcfR("C:\Users\louis\new_repo\GCA_000662435.2.vcf")
# Read the VCF files
vcf1 <- read.vcfR("C:\\Users\\louis\\new_repo\\GCA_000662435.2.vcf")
View(vcf1)
vcf2 <- read.vcfR("C:\\Users\\louis\\new_repo\\Extracted_Variants.vcf")
vcf2 <- read.vcfR("C:\\Users\\louis\\new_repo\\Extracted_Variants_edited.vcf")
# Extract SNP positions
positions1 <- extract.info(vcf1, element = "POS", as.numeric = TRUE)
positions2 <- extract.info(vcf2, element = "POS", as.numeric = TRUE)
# Create data frames for plotting
df1 <- data.frame(Position = positions1, Source = "VCF1")
df2 <- data.frame(Position = positions2, Source = "VCF2")
# Combine the data frames
df <- rbind(df1, df2)
df <- df %>%
mutate(Bin = cut(Position, breaks = seq(min(Position), max(Position), by = 10000), labels = FALSE)) %>%
group_by(Source, Bin) %>%
summarise(Count = n())
View(df1)
View(df2)
View(vcf1)
head(vcf1)
positions1
# Read the VCF files
vcf1 <- read.vcfR("C:\\Users\\louis\\new_repo\\GCA_000662435.2.vcf")
# Read the VCF files
vcf <- read.vcfR("C:\\Users\\louis\\genomeGit\\repo_tests\\sac_test_2019\\GCA_000662435.2.vcf", verbose = FALSE)
gff <- read.table("C:\\Users\\louis\\genomeGit\\repo_tests\\sac_test_2019\\GCA_000662435.2.gff", sep="\t", quote="")
dna <- ape::read.dna("C:\\Users\\louis\\genomeGit\\repo_tests\\sac_test_2019\\GCA_000662435.2.fasta", format = "fasta")
dna <- ape::read.dna("C:\\Users\\louis\\genomeGit\\repo_tests\\sac_test_2019\\GCA_000662435.2.fna", format = "fasta")
chrom <- create.chromR(name='Supercontig', vcf=vcf, seq=dna, ann=gff)
plot(chrom)
chrom <- proc.chromR(chrom, verbose=TRUE)
plot(chrom)
chromoqc(chrom, dp.alpha=20)
vcf <- read.vcfR("C:\\Users\\louis\\new_repo\\Extracted_Variants_edited.vcf", verbose = FALSE)
gff <- read.table("C:\\Users\\louis\\new_repo\\Extracted_Annotation.gff", sep="\t", quote="")
dna <- ape::read.dna("C:\\Users\\louis\\new_repo\\GCA_000976665.2.fna", format = "fasta")
chrom <- create.chromR(name='Supercontig', vcf=vcf, seq=dna, ann=gff)
chrom <- proc.chromR(chrom, verbose=TRUE)
chromoqc(chrom, dp.alpha=20)
vcf <- read.vcfR("C:\\Users\\louis\\genomeGit\\repo_tests\\sac_test_2019\\GCA_000662435.2.vcf", verbose = FALSE)
gff <- read.table("C:\\Users\\louis\\genomeGit\\repo_tests\\sac_test_2019\\GCA_000662435.2.gff", sep="\t", quote="")
dna <- ape::read.dna("C:\\Users\\louis\\genomeGit\\repo_tests\\sac_test_2019\\GCA_000662435.2.fna", format = "fasta")
chrom <- create.chromR(name='Supercontig', vcf=vcf, seq=dna, ann=gff)
chrom <- proc.chromR(chrom, verbose=TRUE)
plot(chrom)
chromoqc(chrom, dp.alpha=20)
vcf <- read.vcfR("C:\\Users\\louis\\new_repo\\Extracted_Variants_edited.vcf", verbose = FALSE)
gff <- read.table("C:\\Users\\louis\\new_repo\\Extracted_Annotation.gff", sep="\t", quote="")
dna <- ape::read.dna("C:\\Users\\louis\\new_repo\\GCA_000976665.2.fna", format = "fasta")
chrom <- create.chromR(name='Supercontig', vcf=vcf, seq=dna, ann=gff)
chrom <- proc.chromR(chrom, verbose=TRUE)
plot(chrom)
chromoqc(chrom, dp.alpha=20)
# Imports
library(gplots)
library(devtools)
library(Biobase)
library(RSkittlerBrewer)
library(org.Hs.eg.db)
library(AnnotationDbi)
# RSkittlerBrewer
biocLite("alyssafrazee/RSkittleBrewer")
# RSkittlerBrewer
devtools::install_github("alyssafrazee/RSkittleBrewer")
library(RSkittleBrewer)
con = url("http://bowtie-bio.sourceforge.net/recount/ExpressionSets/bodymap_eset.RData")
# Data download
con = url("http://bowtie-bio.sourceforge.net/recount/ExpressionSets/bodymap_eset.RData")
load(file=con)
close(con)
# Data import
bm = bodymap.eset
pdata <- pData(bm)
edata <- exprs(bm)
fdata <- fData(bm)
# Exploratory statistics
table(pdata$gender)
table(pdata$gender, pdata$race)
summary(edata)
table(pdata$age, useNA='ifany')
table(pdata$gender, pdata$race, useNA = 'ifany')
summary(fdata)
head(fdata, rows=14)
# NA check
sum(is.na(edata))
rowSums(is.na(edata))
table(gene_na)
gene_na <- rowSums(is.na(edata))
table(gene_na)
# Boxplot
head(edata)
# Boxplot
head(edata][1,])
# Boxplot
head(edata][,1])
# Boxplot
head(edata[,1])
dim(edata)
boxplot(edata)
boxplot(edata[,1])
boxplot(log2(edata[,1]))
boxplot(log2(edata[,1]+1))
boxplot(log2(edata+1), col=2, range=0)
# Overlay a logged histogram of expression level freqdensity
plot(density(log2(edata[,1]+1)), col=1)
lines(density(log2(edata[,1]+1)), col=2)
# Overlay a logged histogram of expression level freqdensity
plot(density(log2(edata[,1]+1)), col=1)
lines(density(log2(edata[,2]+1)), col=2)
qqplot(log2(edata[,1]+1),log2(edata[,2]+1),col=3)
mm <- log2(edata[,1]+1) - log2(edata[,2]+1)
aa <- log2(edata[,1]+1) + log2(edata[,2]+1)
plot(aa,mm,col=2)
View(edata)
con =url("http://bowtie-bio.sourceforge.net/recount/ExpressionSets/bottomly_eset.RData")
load(file=con)
close(con)
bot = bottomly.eset
pdata_bot=pData(bot)
con =url("http://bowtie-bio.sourceforge.net/recount/ExpressionSets/bodymap_eset.RData")
load(file=con)
close(con)
bm = bodymap.eset
pdata_bm=pData(bm)
# The bottomly data has biological replicates for each group but the Bodymap data does not
head(pdata_bot)
table(pdata_bot$num.tech.reps)
table(pdata_bm$num.tech.reps)
# One technical replicate per sample
table(pdata_bot$num.tech.reps, useNA='ifany')
# Multiple tech replicates per sample
table(pdata_bm$num.tech.reps, useNA='ifany')
# The bottomly data has biological replicates for each group but the Bodymap data does not
head(pdata_bot)
head(pdata_bm)
table(pdata_bot$strain)
table(pdata_bm$tissue.type)
con =url("http://bowtie-bio.sourceforge.net/recount/ExpressionSets/bodymap_eset.RData")
load(file=con)
close(con)
bm = bodymap.eset
edata = exprs(bm)
library(gplots)
library(devtools)
library(Biobase)
library(org.Hs.eg.db)
library(AnnotationDbi)
# RSkittlerBrewer
library(RSkittleBrewer)
# Setting up colouring for graphs
tropical <- c('darkorange','dodgerblue','hotpink','limegreen','yellow')
palette(tropical)
# Make data points filled
par(pch=19)
con =url("http://bowtie-bio.sourceforge.net/recount/ExpressionSets/bodymap_eset.RData")
load(file=con)
close(con)
bm = bodymap.eset
edata = exprs(bm)
row_sums = rowSums(edata)
index = which(rank(-row_sums) < 500 )
heatmap(edata[index,],Rowv=NA)
row_sums = rowSums(edata)
edata = edata[order(row_sums),]
index = which(rank(-row_sums) < 500 )
heatmap(edata[index,],Rowv=NA,Colv=NA)
row_sums = rowSums(edata)
edata = edata[order(row_sums),]
index = which(rank(-row_sums) < 500 )
heatmap(edata[index,],Rowv=NA,Colv=NA)
# Question 8
# Make an MA-plot of the first sample versus the second sample using the log2 transform and rlog from DESeq2
# Which kind of genes appear most different in each plot?
con =url("http://bowtie-bio.sourceforge.net/recount/ExpressionSets/bodymap_eset.RData")
load(file=con)
close(con)
bm = bodymap.eset
pdata = pData(bm)
edata = exprs(bm)
head(edata)
# MA plot (log2)
mm = log2(edata[,1]+1) - log2(edata[,1]+1)
aa = log2(edata[,2]+1) + log2(edata[,2]+1)
plot(mm,aa,col=2)
mm = log2(edata[,1]+1) - log2(edata[,2]+1)
aa = log2(edata[,1]+1) + log2(edata[,2]+1)
plot(mm,aa,col=2)
mm = log2(edata[,1]+1) - log2(edata[,2]+1)
aa = log2(edata[,1]+1) + log2(edata[,2]+1)
plot(aa,mm,col=2)
# MA plot (rlog)
library(DESeq2)
mm = rlog(edata[,1]+1) - rlog(edata[,2]+1)
mm = log2(edata[,1]+1) - log2(edata[,2]+1)
aa = log2(edata[,1]+1) + log2(edata[,2]+1)
plot(aa,mm,col=2)
mm = rlog(edata[,1]+1) - rlog(edata[,2]+1)
?rlog
head(pdata)
pData(bm)
dds <- DESeqDataSetFromMatrix(countData = edata, colData = pData(bm), design = ~ 1)
rlog_data <- rlog(dds, blind = TRUE)
# Calculate MA values
mm_rlog = assay(rlog_data)[,1] - assay(rlog_data)[,2]
aa_rlog = assay(rlog_data)[,1] + assay(rlog_data)[,2]
plot(aa_rlog, mm_rlog, col=2, main="MA-plot (rlog)", xlab="Mean Expression (rlog)", ylab="Difference (rlog)")
plot(aa,mm,col=2)
points(aa_rlog, mm_rlog, col=2, main="MA-plot (rlog)", xlab="Mean Expression (rlog)", ylab="Difference (rlog)")
plot(aa,mm,col=2)
points(aa_rlog, mm_rlog, col=3, main="MA-plot (rlog)", xlab="Mean Expression (rlog)", ylab="Difference (rlog)")
# Imports
library(gplots)
library(devtools)
library(Biobase)
library(org.Hs.eg.db)
library(AnnotationDbi)
# RSkittlerBrewer
# devtools::install_github("alyssafrazee/RSkittleBrewer")
library(RSkittleBrewer)
set.seed(1235)
# How many clusters
table(pdata$study)
# Final Question
con =url("http://bowtie-bio.sourceforge.net/recount/ExpressionSets/montpick_eset.RData")
load(file=con)
close(con)
mp = montpick.eset
pdata=pData(mp)
edata=as.data.frame(exprs(mp))
fdata = fData(mp)
# Cluster the samples using k-means clustering after applying the log2
# log2 transform (be sure to add 1). Set a seed for reproducible results
# (use set.seed(1235)
# If you choose two clusters, do you get the same two clusters as you get if you use the
# cutree function to cluster the samples into two groups?
# Which cluster matches most closely to the study labels?
set.seed(1235)
# How many clusters
table(pdata$study)
# Log transform
edata <- log2(head(edata,1000)+1)
# Kmeans, 2 clusters
kmeans1 <- kmeans(edata, centers=2)
# HClust
dist1 <- dist(edata)
hc1 <- hclust(dist1)
cutree_clusters <- cutree(hc, k=2)
cutree_clusters <- cutree(hc1, k=2)
# Compare hClust to Kmeans
table(kmeans1$cluster, cutree_clusters)
# Compare hClust to realval
table(kmeans1$cluster, pdata$study)
# Compare hClust to realval
table(kmeans1$cluster, head(pdata,1000)$study)
pdata <- head(pdata,1000)
dim(pdata)
dim(kmeans1$cluster)
length(kmeans1$cluster)
length(cutree_clusters)
con =url("http://bowtie-bio.sourceforge.net/recount/ExpressionSets/montpick_eset.RData")
load(file=con)
close(con)
mp = montpick.eset
pdata=pData(mp)
edata=as.data.frame(exprs(mp))
fdata = fData(mp)
# Cluster the samples using k-means clustering after applying the log2
# log2 transform (be sure to add 1). Set a seed for reproducible results
# (use set.seed(1235)
# If you choose two clusters, do you get the same two clusters as you get if you use the
# cutree function to cluster the samples into two groups?
# Which cluster matches most closely to the study labels?
set.seed(1235)
# How many clusters
table(pdata$study)
# Log transform
edata <- log2(head(edata,1000)+1)
# Kmeans, 2 clusters
kmeans1 <- kmeans(edata, centers=2)
# HClust
dist1 <- dist(edata)
hc1 <- hclust(dist1)
cutree_clusters <- cutree(hc1, k=2)
# Compare hClust to Kmeans
table(kmeans1$cluster, cutree_clusters)
dim(pdata)
pdata <- head(pdata,1000)
dim(pdata)
length(kmeans1$cluster)
length(cutree_clusters)
dim(edata)
# Final Question
con =url("http://bowtie-bio.sourceforge.net/recount/ExpressionSets/montpick_eset.RData")
load(file=con)
close(con)
mp = montpick.eset
pdata=pData(mp)
edata=as.data.frame(exprs(mp))
fdata = fData(mp)
# Cluster the samples using k-means clustering after applying the log2
# log2 transform (be sure to add 1). Set a seed for reproducible results
# (use set.seed(1235)
# If you choose two clusters, do you get the same two clusters as you get if you use the
# cutree function to cluster the samples into two groups?
# Which cluster matches most closely to the study labels?
set.seed(1235)
# How many clusters
table(pdata$study)
# Log transform
edata <- log2(head(edata,1000)+1)
head(edata)
head(t(edata))
set.seed(1235)
# How many clusters
table(pdata$study)
# Log transform
edata <- t(log2(edata+1))
# Kmeans, 2 clusters
kmeans1 <- kmeans(edata, centers=2)
# HClust
dist1 <- dist(edata)
hc1 <- hclust(dist1)
cutree_clusters <- cutree(hc1, k=2)
# Compare hClust to Kmeans
table(kmeans1$cluster, cutree_clusters)
length(kmeans1$cluster)
length(cutree_clusters)
dim(pdata)
table(pdata$study,cutree_clusters)
table(pdata$study,kmeans1$cluster)
# Clustering Assignment
pwd()
# Clustering Assignment
setwd('C:\\Users\\louis\\opencourse\\analytics_edge\\clustering\dailykos.csv')
# Clustering Assignment
setwd('C:\\Users\\louis\\opencourse\\analytics_edge\\clustering')
library(readr)
dailykos <- read_csv("dailykos.csv")
View(dailykos)
dim(dailykos)
max_k <- 15
wss <- numeric(max_k)
# Loop through k and compute k-means clustering
for (k in 1:max_k) {
set.seed(123)
kmeans_res <- kmeans(dailykos, centers = k, nstart = 10)
# Sum of squares
wss[k] <- kmeans_res$tot.withinss
}
# MIT OpenCourseWare; The Analytics Edge
# Louis Hague, 05/11/2024
# Answers within the present script may differ from those on the MIT website
# as the entire dataset was not used due to its large size
# Clustering Assignment
setwd('C:\\Users\\louis\\opencourse\\analytics_edge\\clustering')
# Import data
# Column: Instance of word that has appeared in at least 50 different articles (1,545 words in total).
# Row: Instance of a document
# The set of  words has been trimmed
# For each document, the variable values are the number of times that word appeared in the document.
library(readr)
dailykos <- read_csv("dailykos.csv")
dim(dailykos)
# My PC will run out of RAM with that dataset so we will half the rowlen
# dailykos_samp <- head(dailykos,3450)
# Problem 1.1
# Compute the distances (using method=“euclidean”), hclust to build the model (using method=“ward.D2”)
# The reason behind the long computation is because each row must have its euclidean distance compared
# to each other point, there are 3430 documents in the dataset (3450*3450=5.8million comparisons)
dist1 <- dist(dailykos,method="euclidean")
hclust1 <- hclust(dist1,method="ward.D2")
plot(hclust1)
# Problem 1.2-3
# When categorising news articles into groups it might seem as if 7-8 groups would be more
# appropriate. However, to estimate the best number of clusters we could use the
# 'Elbow method', 'Silhouette Score', we will go off of the dendrogram in this instance
heirGroups <- cutree(hclust1, k=7)
# 1 has the most articles clustered, 7 has the fewest articles clustered
table(heirGroups)
# Problem 1.4
# What is the most commmon word within each cluster
library(dplyr)
Cluster1 <- dailykos %>% filter(heirGroups == 1)
Cluster2 <- dailykos %>% filter(heirGroups == 2)
Cluster3 <- dailykos %>% filter(heirGroups == 3)
Cluster4 <- dailykos %>% filter(heirGroups == 4)
Cluster5 <- dailykos %>% filter(heirGroups == 5)
Cluster6 <- dailykos %>% filter(heirGroups == 6)
Cluster7 <- dailykos %>% filter(heirGroups == 7)
# Common words
Clust1_common_words <- tail(sort(colMeans(Cluster1)))
Clust2_common_words <- tail(sort(colMeans(Cluster2)))
Clust3_common_words <- tail(sort(colMeans(Cluster3)))
Clust4_common_words <- tail(sort(colMeans(Cluster4)))
Clust5_common_words <- tail(sort(colMeans(Cluster5)))
Clust6_common_words <- tail(sort(colMeans(Cluster6)))
Clust7_common_words <- tail(sort(colMeans(Cluster7)))
Clust1_common_words
Clust2_common_words
Clust3_common_words
Clust4_common_words
Clust5_common_words
Clust6_common_words
Clust7_common_words
# Problem 2.1
set.seed(1000)
kmen1 <- kmeans(dailykos)
kmen1 <- kmeans(dailykos,centers = 7)
table(kmen1$cluster)
# Problem 2.2
kmen1$cluster
# Problem 2.2
kmeans1 <- dailykos %>% filter(kmen1$cluster == 1)
kmeans1 <- dailykos %>% filter(kmen1$cluster == 1)
kmeans1 <- dailykos %>% filter(kmen1$cluster == 1)
kmeans1 <- dailykos %>% filter(kmen1$cluster == 1)
kmeans1 <- dailykos %>% filter(kmen1$cluster == 1)
kword1 <- colMeans(kmeans1)
kword1
kword1 <- tail(sort(colMeans(kmeans1)))
kword1
kword1 <- tail(sort(colMeans(kmeans1)))
kword1 <- tail(sort(colMeans(kmeans1)))
kword1 <- tail(sort(colMeans(kmeans1)))
kword2 <- tail(sort(colMeans(kmeans2)))
kmeans1 <- dailykos %>% filter(kmen1$cluster == 1)
kmeans2 <- dailykos %>% filter(kmen1$cluster == 2)
kmeans3 <- dailykos %>% filter(kmen1$cluster == 3)
kmeans4 <- dailykos %>% filter(kmen1$cluster == 4)
kmeans5 <- dailykos %>% filter(kmen1$cluster == 5)
kmeans6 <- dailykos %>% filter(kmen1$cluster == 6)
kmeans7 <- dailykos %>% filter(kmen1$cluster == 7)
kword1 <- tail(sort(colMeans(kmeans1)))
kword2 <- tail(sort(colMeans(kmeans2)))
kword3 <- tail(sort(colMeans(kmeans3)))
kword4 <- tail(sort(colMeans(kmeans4)))
kword5 <- tail(sort(colMeans(kmeans5)))
kword6 <- tail(sort(colMeans(kmeans6)))
kword7 <- tail(sort(colMeans(kmeans7)))
kword1
kword2
kword3
kword4
kword5
kword6
kword7
# Problem 2.3
table(kmen1$cluster, heirGroups)
set.seed(1000)
kmen1 <- kmeans(dailykos,centers = 7)
table(kmen1$cluster)
# How many articles are in cluster 3: 300
# Cluster 4 has the most observations
# Cluster 5 has the fewest observations
# Problem 2.2
kmeans1 <- dailykos %>% filter(kmen1$cluster == 1)
kmeans2 <- dailykos %>% filter(kmen1$cluster == 2)
kmeans3 <- dailykos %>% filter(kmen1$cluster == 3)
kmeans4 <- dailykos %>% filter(kmen1$cluster == 4)
kmeans5 <- dailykos %>% filter(kmen1$cluster == 5)
kmeans6 <- dailykos %>% filter(kmen1$cluster == 6)
kmeans7 <- dailykos %>% filter(kmen1$cluster == 7)
kword1 <- tail(sort(colMeans(kmeans1)))
kword2 <- tail(sort(colMeans(kmeans2)))
kword3 <- tail(sort(colMeans(kmeans3)))
kword4 <- tail(sort(colMeans(kmeans4)))
kword5 <- tail(sort(colMeans(kmeans5)))
kword6 <- tail(sort(colMeans(kmeans6)))
kword7 <- tail(sort(colMeans(kmeans7)))
kword1
kword2
kword3
kword4
kword5
kword6
kword7
# Which k-means cluster best corresponds to the Iraq War: Cluster 6
# Which k-means cluster best corresponds to the democratic party: Cluster 5
# Problem 2.3
table(kmen1$cluster, heirGroups)
# HClust 3 best represents kmeans cluster 2
# HClust 2 best represents kmeans cluster 3
